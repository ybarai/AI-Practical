import pandas as pd

# Load the dataset
dataset = pd.read_csv('shopping.csv')

# Replace the values in the dataset
dataset['Month'].replace(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'June', 'Jul', 'Aug', 'Sep', 'Oct
dataset['VisitorType'].replace(['Returning_Visitor', 'New_Visitor', 'Other'], [0, 1, 1], inpla
dataset['Weekend'].replace([False, True], [0, 1], inplace=True)
dataset['Revenue'].replace([False, True], [0, 1], inplace=True)

dataset.head()




n = dataset.shape[0]

# Shuffle the dataset
dataset.sample(frac=1)

ratio = 0.998

# Split dataset into training and test sets
train = dataset[:int(n*ratio)]
test = dataset[int(n*ratio):]

train.shape, test.shape


#KNN

# function to calculate euclidean distance
def eucDis(x, y):
	dist = 0
	for i in range(len(x)):
		dist += (x[i] - y[i])**2
	return dist**0.5



# function to implement k-NN
def knn(k, train, test):
	# list to store predictions
	predictions = []
	for i in range(len(test)):
		# list to store distances
		distances = []
		for j in range(len(train)):
		
			# select the features
			x = train.iloc[j][:-1]
			y = test.iloc[i][:-1]
			dist = eucDis(x, y)
			
			# append the distance and the label
			distances.append((dist, train.iloc[j]['Revenue']))
			
		# sort the distances
		distances.sort()
		
		# select the k-nearest neighbors
		neighbors = distances[:k]
		count = 0
		for neighbor in neighbors:
			count += neighbor[1]
		predictions.append(1 if count > k/2 else 0)
	return predictions

k = 5
# get the predictions
predictions = knn(k, train, test)

true_pos = 0
true_neg = 0
false_pos = 0
false_neg = 0

# calculate the metrics
for i in range(len(predictions)):
	if predictions[i] == test.iloc[i]['Revenue']:
		if predictions[i] == 1:
			true_pos += 1
		else:
			true_neg += 1
	else:
		if predictions[i] == 1:
			false_pos += 1
		else:
f			alse_neg += 1

accuracy = (true_pos + true_neg) / len(predictions)
precision = true_pos / (true_pos + false_pos) if (true_pos + false_pos) > 0 else 0
recall = true_pos / (true_pos + false_neg) if (true_pos + false_neg) > 0 else 0
f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

# print the metrics
print("Accuracy:", accuracy)
print("Precision: ", precision)
print("Recall: ", recall)
print("F1 Score: ", f1)

#Decision Tree

from sklearn.tree import DecisionTreeClassifier

n = dataset.shape[0]

# Shuffle the dataset
dataset.sample(frac=1)

ratio = 0.75

# Split dataset into training and test sets
train = dataset[:int(n*ratio)]
test = dataset[int(n*ratio):]

train.shape, test.shape

# Split features into X_train, X_test, y_train, y_test and target variable
X_train = train.drop(columns='Revenue')
y_train = train['Revenue']
X_test = test.drop(columns='Revenue')
y_test = test['Revenue']

# Train decision tree classifier
decision_tree = DecisionTreeClassifier()
decision_tree.fit(X_train, y_train)

# Make predictions
predictions = decision_tree.predict(X_test)

# calculate metrics
true_pos, true_neg, false_pos, false_neg = 0, 0, 0, 0


for i in range(len(predictions)):
	if predictions[i] == y_test.iloc[i]:
		if predictions[i] == 1:
			true_pos += 1
		else:
			true_neg += 1
	else:
		if predictions[i] == 1:
			false_pos += 1
		else:
			false_neg += 1

accuracy = (true_pos + true_neg) / len(predictions)
precision = true_pos / (true_pos + false_pos) if (true_pos + false_pos) > 0 else 0
recall = true_pos / (true_pos + false_neg) if (true_pos + false_neg) > 0 else 0
f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

# Print metrics
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)



#Naive Bayes

from sklearn.naive_bayes import GaussianNB

# Initialize Naive Bayes
nb_model = GaussianNB()
nb_model.fit(X_train, y_train)

# make predictions
y_pred = nb_model.predict(X_test)

# calculate the metrics
true_pos, true_neg, false_pos, false_neg = 0, 0, 0, 0
for i in range(len(y_test)):
	if y_pred[i] == y_test.iloc[i]:
		if y_pred[i] == 1:
			true_pos += 1
		else:
			true_neg += 1
	else:
		if y_pred[i] == 1:
			false_pos += 1
		else:
			false_neg += 1
			
accuracy = (true_pos + true_neg) / len(y_test)
precision = true_pos / (true_pos + false_pos) if (true_pos + false_pos) > 0 else 0
recall = true_pos / (true_pos + false_neg) if (true_pos + false_neg) > 0 else 0
f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

# print metrics
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)